{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8768b909-6017-4deb-829b-c1d040c230df",
   "metadata": {},
   "source": [
    "### Scrape indeed\n",
    "##### Lakkas Giannis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8b78d-fd0a-4e84-b66a-8a41f52d0669",
   "metadata": {},
   "source": [
    "*  Basic imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846565b-35be-4bb2-8310-58ec39d65358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U selenium\n",
    "# !pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f9f13b-b1e8-43a9-a2dc-0b099b92346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1af97d-86ee-4840-b98d-ef7ef54205fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creation of a folder to save the images(the logo from this notebook and the rest from the second(the summarizer))\n",
    "\"\"\"\n",
    "if not os.path.exists('customer_analytics1'):\n",
    "    os.makedirs('customer_analytics1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3c5db3-6c87-4e94-89cc-ee0d90ced4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracts descriptions, the ratings and the text from the page\n",
    "\"\"\"\n",
    "def get_data_from_page(writer:csv.writer):\n",
    "    \n",
    "    reviews=driver.find_elements(by=By.CSS_SELECTOR, value='[itemprop=\"review\"]')\n",
    "    print(\"Reviews:\", len(reviews))\n",
    "    for review in reviews:\n",
    "        \n",
    "        descr, text, rating = 'NA','NA','NA'\n",
    "        # extract the description(date, job role, region)\n",
    "        try: \n",
    "            descr=review.find_element(by=By.CSS_SELECTOR, value='[itemprop=\"author\"]').text        \n",
    "        except NoSuchElementException as e: # headline or link could not be found\n",
    "            print('could not extract headline')\n",
    "        # extract the text    \n",
    "        try: \n",
    "            text = review.find_element(by=By.CSS_SELECTOR, value='[itemprop=\"reviewBody\"]').text\n",
    "        except NoSuchElementException as e: # headline or link could not be found\n",
    "            print('could not extract text')\n",
    "        # extract the rating \n",
    "        try: \n",
    "            rating = review.find_element(by=By.CSS_SELECTOR, value='[itemprop=\"reviewRating\"]').text\n",
    "        except NoSuchElementException as e: # headline or link could not be found\n",
    "            print('could not extract rating')  \n",
    "        # save the extracted description, text, rating in a row \n",
    "        writer.writerow([descr, text, rating])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6773ab-7696-42d2-a468-1ac555335f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracts the company's logo from the main page.\n",
    "\"\"\"\n",
    "def scrape_logo(url:str, query: str):\n",
    "    logo = driver.find_element(by=By.CSS_SELECTOR, value='[itemprop=\"image\"]')\n",
    "    logo_link = logo.get_attribute(\"src\")\n",
    "    urllib.request.urlretrieve(logo_link, \"customer_analytics1/\"+ query + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17693fc5-0abf-4216-a1a5-668ed28987f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(query:str,\n",
    "                delay:int = 2):\n",
    "    # create a csv with name \"<company_name>_data.csv\"\n",
    "    with open(query+'_data.csv', 'w', encoding='utf-8') as fw:\n",
    "        writer = csv.writer(fw, lineterminator='\\n')\n",
    "        #write the headers\n",
    "        writer.writerow(['description','text','rating'])\n",
    "        # search \n",
    "        url='https://www.indeed.com/companies/search?q=' + query\n",
    "\n",
    "        driver.get(url) # visit the page\n",
    "                    \n",
    "        #select the first company(which is closer to our search)\n",
    "        company = driver.find_element(by=By.CSS_SELECTOR, value='[data-tn-section=\"CompaniesRowGroup\"]')\n",
    "        company_results = company.find_elements(by=By.CSS_SELECTOR, value='[data-tn-component=\"CompanyRow\"]')\n",
    "        first_company = company_results[0]\n",
    "        driver.implicitly_wait(2)\n",
    "        driver.find_element(By.LINK_TEXT, 'Reviews').click()\n",
    "\n",
    "        #select all the countries and select lang the english\n",
    "        get_url = driver.current_url\n",
    "        get_url = get_url + '?fcountry=ALL&lang=en'\n",
    "        driver.get(get_url)\n",
    "        \n",
    "        #scrape the company's logo\n",
    "        logo = scrape_logo(url=get_url, query=query)\n",
    "        \n",
    "        #find the number of the company's reviews\n",
    "        total_reviews = driver.find_element(by=By.CSS_SELECTOR, value='[data-testid=\"review-count\"]').text\n",
    "        print(total_reviews)\n",
    "        total_revies_num =  re.findall(r\"[0-9,.]+\", total_reviews.replace(',','').replace('.',''))[0]\n",
    "        print(\"Total Reviews \", total_revies_num)\n",
    "        # calculate the number of pages. \n",
    "        #This number will be used later in order to change pages due to the fact that the site follows a specific pattern (plus 20 for each page)\n",
    "        total_pages = int(total_revies_num) // 20 if int(total_revies_num) % 20 == 0 else (int(total_revies_num) // 20) + 1\n",
    "        print(\"Total Pages \", total_pages)\n",
    "\n",
    "        page_cnt = 1\n",
    "        while True: # keep going until there are no more pages\n",
    "            print('Page: ' + str(page_cnt) + \". Progress: \" + str(round(page_cnt/total_pages, 2)*100) + \"%\") # print current page count\n",
    "            page_cnt += 1 # increment \n",
    "            #extract data from the page\n",
    "            get_data_from_page(writer) \n",
    "            # check if the next button is not presented, this means that there aren't any other pages\n",
    "            if len(driver.find_elements(By.LINK_TEXT, 'Next')) < 1:\n",
    "                break; \n",
    "            # if the button exists, then clink it\n",
    "            next_button = WebDriverWait(driver, delay).until(EC.element_to_be_clickable((By.LINK_TEXT, 'Next')))\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "        fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b4bb77-2832-442a-94f7-0718e33a4956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.maximize_window()\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12ead26-feda-46fa-a262-031a3c69b4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing all 257 reviews\n",
      "Total Reviews  257\n",
      "Total Pages  13\n",
      "Page: 1. Progress: 8.0%\n",
      "Reviews: 21\n",
      "Page: 2. Progress: 15.0%\n",
      "Reviews: 21\n",
      "Page: 3. Progress: 23.0%\n",
      "Reviews: 21\n",
      "Page: 4. Progress: 31.0%\n",
      "Reviews: 21\n",
      "Page: 5. Progress: 38.0%\n",
      "Reviews: 21\n",
      "Page: 6. Progress: 46.0%\n",
      "Reviews: 21\n",
      "Page: 7. Progress: 54.0%\n",
      "Reviews: 21\n",
      "Page: 8. Progress: 62.0%\n",
      "Reviews: 21\n",
      "Page: 9. Progress: 69.0%\n",
      "Reviews: 21\n",
      "Page: 10. Progress: 77.0%\n",
      "Reviews: 21\n",
      "Page: 11. Progress: 85.0%\n",
      "Reviews: 21\n",
      "Page: 12. Progress: 92.0%\n",
      "Reviews: 21\n",
      "Page: 13. Progress: 100.0%\n",
      "Reviews: 17\n"
     ]
    }
   ],
   "source": [
    "scrape('Corteva-Agriscience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7af75-ef63-4145-b1f6-0e0e2a335497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258646de-ba08-4a16-b82e-69a5be4a6e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
